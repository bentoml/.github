# Welcome to BentoML 👋  [![Twitter Follow](https://img.shields.io/twitter/follow/bentomlai?style=social)](https://twitter.com/bentomlai) [![Slack](https://img.shields.io/badge/Slack-Join-4A154B?style=social)](https://l.bentoml.com/join-slack)


[![BentoML](https://github.com/bentoml/.github/assets/489344/bc3938ea-5a44-4cba-9c3f-b1bbb5b4d88b)](http://bentoml.com)


<div align="center">
<a href="http://bentoml.com">Website</a> | <a href="https://docs.bentoml.com">Docs</a> | <a href="https://bentoml.com/blog">Blog</a> | <a href="https://twitter.com/bentomlai">Twitter</a> | <a href="https://l.bentoml.com/join-slack">Community</a>
</div>

## What is BentoML? 👩‍🍳

BentoML is an open-source model serving library for building model inference APIs and multi-model serving systems with any open-source or custom AI models. It comes with everything you need for serving optimization, model packaging, and simplifies production deployment via [☁️ BentoCloud](https://www.bentoml.com/cloud).

- [🍱 BentoML](https://github.com/bentoml/BentoML): The Unified Model Serving Framework
- [🦾 OpenLLM](https://github.com/bentoml/OpenLLM): Self-hosting Large Language Models Made Easy
- [☁️ BentoCloud](https://www.bentoml.com/cloud): Inference Platform for fast-moving AI teams

## Get in touch 💬

👉 [Join our Slack community!](https://l.bentoml.com/join-slack)

👀 Follow us on X [@bentomlai](https://twitter.com/bentomlai) and [LinkedIn](https://www.linkedin.com/company/bentoml/)

📖 Read our [blog](https://www.bentoml.com/blog)
