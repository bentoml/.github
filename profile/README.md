# Welcome to BentoML 👋  [![Twitter Follow](https://img.shields.io/twitter/follow/bentomlai?style=social)](https://twitter.com/bentomlai) [![Slack](https://img.shields.io/badge/Slack-Join-4A154B?style=social)](https://l.bentoml.com/join-slack)

[![BentoML](https://github.com/bentoml/.github/assets/489344/ab1d2af8-220d-4a0a-b509-b6d39c1a7a63)](http://bentoml.com)


<div align="center">
<a href="http://bentoml.com">Website</a> | <a href="https://docs.bentoml.com">Docs</a> | <a href="https://bentoml.com/blog">Blog</a> | <a href="https://twitter.com/bentomlai">Twitter</a> | <a href="https://l.bentoml.com/join-slack">Community</a>
</div>

## What is BentoML? 👩‍🍳

BentoML is an open-source model serving library for building performant and scalable AI applications with Python. It comes with everything you need for serving optimization, model packaging, and production deployment.

*🔨 Build Anywhere with Open-Source:*
- [🍱 BentoML](https://github.com/bentoml/BentoML): The Unified Model Serving Framework
- [🦾 OpenLLM](https://github.com/bentoml/OpenLLM): Self-hosting Large Language Models Made Easy


*🚢 Efficient scaling on your/our Cloud:*
- [☁️ BentoCloud](https://www.bentoml.com/cloud): Inference Platform for enterprise AI teams to build fast, secure, and scalable AI applications.

## Get in touch 💬

👉 [Join our Slack community!](https://l.bentoml.com/join-slack)

👀 Follow us on X [@bentomlai](https://twitter.com/bentomlai) and [LinkedIn](https://www.linkedin.com/company/bentoml/)

📖 Read our [blog](https://www.bentoml.com/blog)
